services:
  # PostgreSQL Database for Airflow and Metrics
  postgres:
    image: postgres:13
    environment:
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - POSTGRES_DB=airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5

  # Redis for Celery (if you want to scale later)
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      retries: 5

  # MLflow Tracking Server for ML Metrics and Model Registry
  mlflow:
    image: python:3.9-slim
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=/mlflow/artifacts
    volumes:
      - mlflow_data:/mlflow
      - ./scripts:/opt/airflow/scripts
    ports:
      - "5000:5000"
    command: >
      bash -c "pip install mlflow psycopg2-binary &&
      psql -h postgres -U airflow -d airflow -c 'CREATE DATABASE mlflow;' 2>/dev/null || true &&
      mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri postgresql://airflow:airflow@postgres:5432/mlflow --default-artifact-root /mlflow/artifacts"

  airflow-init:
    build: .
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__METRICS__STATSD_ON=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./utils:/opt/airflow/utils
      - ./data:/opt/airflow/data
      - ./datamart:/opt/airflow/datamart
    entrypoint: >
      /bin/bash -c "airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true"

  airflow-webserver:
    build: .
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__METRICS__STATSD_ON=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./utils:/opt/airflow/utils
      - ./data:/opt/airflow/data
      - ./datamart:/opt/airflow/datamart
    ports:
      - "8080:8080"
    command: webserver

  airflow-scheduler:
    build: .
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres:5432/airflow
      - AIRFLOW__CORE__FERNET_KEY=PAqBeGJLJTYFzVkOGHWIYXdLO7XdXz5yTdxAGJe9ezM=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__METRICS__STATSD_ON=False
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - airflow_data:/opt/airflow
      - ./dags:/opt/airflow/dags
      - ./scripts:/opt/airflow/scripts
      - ./utils:/opt/airflow/utils
      - ./data:/opt/airflow/data
      - ./datamart:/opt/airflow/datamart
    command: scheduler

  # Prometheus for metrics collection (optional)
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'

  # Grafana for metrics visualization (optional)
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus

  pgadmin:
    image: dpage/pgadmin4
    environment:
      - PGADMIN_DEFAULT_EMAIL=admin@admin.com
      - PGADMIN_DEFAULT_PASSWORD=admin
    ports:
      - "5050:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      postgres:
        condition: service_healthy

  jupyter:
    build: .
    ports:
      - "8888:8888"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./scripts:/opt/airflow/scripts
      - ./utils:/opt/airflow/utils
      - ./model_bank:/opt/airflow/model_bank
      - ./loan.csv:/opt/airflow/loan.csv
    command: >
      bash -c "jupyter lab --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --notebook-dir=/opt/airflow"

volumes:
  airflow_data:
  postgres_data:
  mlflow_data:
  prometheus_data:
  grafana_data:
  pgadmin_data:
